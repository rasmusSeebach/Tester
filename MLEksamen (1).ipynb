{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLEksamen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AEb9W-Uccbw"
      },
      "source": [
        "#Package used in the exam\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from collections import Counter\r\n",
        "\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.patches as mpatches\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "import numpy.matlib\r\n",
        "import matplotlib.patches as mpatches\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import zero_one_loss\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NMKriVhc6ow"
      },
      "source": [
        "#Loading the train and test data\r\n",
        "train = np.loadtxt(\"VSTrain.dt\", delimiter=\",\")\r\n",
        "test = np.loadtxt(\"VSTest.dt\", delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-ytDetidBfL",
        "outputId": "8dc31e5b-89fe-4bf7-bbcc-a4515a5d7399"
      },
      "source": [
        "# Splitting the training and test data into features and classes\r\n",
        "x_train = train[:, :-1]\r\n",
        "y_train = train[:, -1]\r\n",
        "\r\n",
        "x_test = test[:, :-1]\r\n",
        "y_test = test[:, -1]\r\n",
        "\r\n",
        "#Counting the frequency divided with the total amount of data point for each class in training and test data\r\n",
        "tmp = dict(Counter(y_train))\r\n",
        "tmp1 = sorted(tmp)\r\n",
        "for key in tmp1:\r\n",
        "    print(\"Frequency for \", key, \" divided with total amount of data points is \",tmp[key]/len(y_train))\r\n",
        "\r\n",
        "print(\"---------------------------------------------\")\r\n",
        "tmp2 = dict(Counter(y_test))\r\n",
        "tmp21 = sorted(tmp2)\r\n",
        "for key in tmp21:\r\n",
        "    print(\"Frequency for \", key, \" divided with total amount of data points is \",tmp2[key]/len(y_train))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequency for  0.0  divided with total amount of data points is  0.08819714656290532\n",
            "Frequency for  1.0  divided with total amount of data points is  0.028534370946822308\n",
            "Frequency for  2.0  divided with total amount of data points is  0.0012970168612191958\n",
            "Frequency for  3.0  divided with total amount of data points is  0.1245136186770428\n",
            "Frequency for  4.0  divided with total amount of data points is  0.02204928664072633\n",
            "Frequency for  5.0  divided with total amount of data points is  0.0648508430609598\n",
            "Frequency for  6.0  divided with total amount of data points is  0.07782101167315175\n",
            "Frequency for  7.0  divided with total amount of data points is  0.01297016861219196\n",
            "Frequency for  8.0  divided with total amount of data points is  0.03501945525291829\n",
            "Frequency for  9.0  divided with total amount of data points is  0.07522697795071336\n",
            "Frequency for  10.0  divided with total amount of data points is  0.011673151750972763\n",
            "Frequency for  11.0  divided with total amount of data points is  0.027237354085603113\n",
            "Frequency for  12.0  divided with total amount of data points is  0.02464332036316472\n",
            "Frequency for  13.0  divided with total amount of data points is  0.011673151750972763\n",
            "Frequency for  14.0  divided with total amount of data points is  0.027237354085603113\n",
            "Frequency for  15.0  divided with total amount of data points is  0.03372243839169909\n",
            "Frequency for  16.0  divided with total amount of data points is  0.029831387808041506\n",
            "Frequency for  17.0  divided with total amount of data points is  0.03372243839169909\n",
            "Frequency for  18.0  divided with total amount of data points is  0.007782101167315175\n",
            "Frequency for  19.0  divided with total amount of data points is  0.01297016861219196\n",
            "Frequency for  20.0  divided with total amount of data points is  0.0038910505836575876\n",
            "Frequency for  21.0  divided with total amount of data points is  0.009079118028534372\n",
            "Frequency for  22.0  divided with total amount of data points is  0.10635538261997406\n",
            "Frequency for  23.0  divided with total amount of data points is  0.08819714656290532\n",
            "Frequency for  24.0  divided with total amount of data points is  0.041504539559014265\n",
            "---------------------------------------------\n",
            "Frequency for  0.0  divided with total amount of data points is  0.09857328145265888\n",
            "Frequency for  1.0  divided with total amount of data points is  0.02594033722438392\n",
            "Frequency for  2.0  divided with total amount of data points is  0.00648508430609598\n",
            "Frequency for  3.0  divided with total amount of data points is  0.12321660181582361\n",
            "Frequency for  4.0  divided with total amount of data points is  0.007782101167315175\n",
            "Frequency for  5.0  divided with total amount of data points is  0.057068741893644616\n",
            "Frequency for  6.0  divided with total amount of data points is  0.08300907911802853\n",
            "Frequency for  7.0  divided with total amount of data points is  0.019455252918287938\n",
            "Frequency for  8.0  divided with total amount of data points is  0.038910505836575876\n",
            "Frequency for  9.0  divided with total amount of data points is  0.07263294422827497\n",
            "Frequency for  10.0  divided with total amount of data points is  0.005188067444876783\n",
            "Frequency for  11.0  divided with total amount of data points is  0.023346303501945526\n",
            "Frequency for  12.0  divided with total amount of data points is  0.01297016861219196\n",
            "Frequency for  13.0  divided with total amount of data points is  0.02464332036316472\n",
            "Frequency for  14.0  divided with total amount of data points is  0.0311284046692607\n",
            "Frequency for  15.0  divided with total amount of data points is  0.03761348897535668\n",
            "Frequency for  16.0  divided with total amount of data points is  0.03631647211413749\n",
            "Frequency for  17.0  divided with total amount of data points is  0.018158236057068743\n",
            "Frequency for  18.0  divided with total amount of data points is  0.010376134889753566\n",
            "Frequency for  19.0  divided with total amount of data points is  0.00648508430609598\n",
            "Frequency for  20.0  divided with total amount of data points is  0.005188067444876783\n",
            "Frequency for  21.0  divided with total amount of data points is  0.007782101167315175\n",
            "Frequency for  22.0  divided with total amount of data points is  0.11284046692607004\n",
            "Frequency for  23.0  divided with total amount of data points is  0.09987029831387809\n",
            "Frequency for  24.0  divided with total amount of data points is  0.03501945525291829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_cywP8cdrIa",
        "outputId": "661a74de-346e-4a07-c3a7-bde13c64980a"
      },
      "source": [
        "# printing the amount of examples each class will have after removel of data points\r\n",
        "train_arr=[]\r\n",
        "for key in tmp:\r\n",
        "    if(tmp[key]>64):\r\n",
        "        train_arr.append(key)\r\n",
        "        print(\"Label \",key,\" has\", tmp[key], \" training examples and \", tmp2[key], \" test examples\")\r\n",
        "\r\n",
        "print(train_arr)\r\n",
        "\r\n",
        "# choosing the classes with 65 or more data points\r\n",
        "x_train1 = []\r\n",
        "y_train1 = []\r\n",
        "\r\n",
        "x_test1 = []\r\n",
        "y_test1 = []\r\n",
        "\r\n",
        "for i in range(len(y_train)):\r\n",
        "    for k in range(len(train_arr)):\r\n",
        "        if (y_train[i] == train_arr[k]):\r\n",
        "            x_train1.append(x_train[i])\r\n",
        "            y_train1.append(y_train[i])\r\n",
        "\r\n",
        "for i in range(len(y_test)):\r\n",
        "    for k in range(len(train_arr)):\r\n",
        "        if (y_test[i] == train_arr[k]):\r\n",
        "            x_test1.append(x_test[i])\r\n",
        "            y_test1.append(y_test[i])\r\n",
        "\r\n",
        "x1 = np.array(x_train1) \r\n",
        "y1 = np.array(y_train1) \r\n",
        "\r\n",
        "xtest1 = np.array(x_test1)\r\n",
        "ytest1 = np.array(y_test1)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label  0.0  has 68  training examples and  76  test examples\n",
            "Label  22.0  has 82  training examples and  87  test examples\n",
            "Label  23.0  has 68  training examples and  77  test examples\n",
            "Label  3.0  has 96  training examples and  95  test examples\n",
            "[0.0, 22.0, 23.0, 3.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5Gfclk6jBCk",
        "outputId": "0c97acb3-70f5-4989-b6dd-a76f52c406c8"
      },
      "source": [
        "#Normalizing the data. Same functions as in assignment 4\r\n",
        "mean = []\r\n",
        "var = []\r\n",
        "for i in range(x1.shape[1]):\r\n",
        "    tmp = x1[:,i]\r\n",
        "    mean.append(np.mean(tmp))\r\n",
        "    var.append(np.var(tmp))\r\n",
        "\r\n",
        "normal = np.zeros((314, 61), dtype=object)\r\n",
        "\r\n",
        "def normal1(data):\r\n",
        "    x_train1 = np.zeros_like(data)\r\n",
        "\r\n",
        "    for i in range(data.shape[1]):\r\n",
        "        tmp1 = data[:,i]\r\n",
        "        x_train1[:,i] = (tmp1-mean[i])/np.sqrt(var[i])\r\n",
        "        normal[i,0] = \"%.5f\" % np.mean(x_train1[:, i])\r\n",
        "        normal[i,1] = \"%.5f\" % np.var(x_train1[:, i])\r\n",
        "        #print(\"Mean: \", normal[i,0],\" Var: \", normal[i,1])\r\n",
        "    return x_train1\r\n",
        "\r\n",
        "normal1(x1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.01752054, -0.11003752,  0.39324135, ...,  2.49739366,\n",
              "         2.61870994,  0.39958652],\n",
              "       [-0.66660712, -0.11003752, -0.68802212, ..., -0.64611458,\n",
              "        -0.68630225, -0.35443278],\n",
              "       [ 0.43724228, -0.11003752,  3.48402642, ...,  0.63904954,\n",
              "         0.77693232,  0.15071849],\n",
              "       ...,\n",
              "       [-0.52691002, -0.11003752,  0.44494398, ..., -0.61362851,\n",
              "        -0.63349213,  0.0338409 ],\n",
              "       [ 0.178843  , 10.46977656, -0.80195904, ..., -0.15573477,\n",
              "        -0.44131782, -2.0395886 ],\n",
              "       [-0.30468664, -0.11003752,  0.80820035, ..., -0.34664124,\n",
              "        -0.20796884,  1.16773001]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uyGxXkjhrwC4",
        "outputId": "c86c8d6f-f4dc-46f0-b21e-4e153b6e8811"
      },
      "source": [
        "#Making the PCA analysis\r\n",
        "pca = PCA()\r\n",
        "pC = pca.fit_transform(normal1(x1))\r\n",
        "x_coor, y_coor = pC[:,0], pC[:,1]\r\n",
        "\r\n",
        "#Plotting the result as scatter plot\r\n",
        "plt.scatter(x_coor, y_coor, c=['b' if i==0 else 'r' if i ==22 else 'black' if i==23 else 'g' for i in y1], s=10)\r\n",
        "d1 = mpatches.Patch(color='b', label='label 0')\r\n",
        "d2 = mpatches.Patch(color='r', label='label 22')\r\n",
        "d3 = mpatches.Patch(color='black', label='label 23')\r\n",
        "d4 = mpatches.Patch(color='g', label='label 3')\r\n",
        "plt.legend(handles=[d1, d2, d3, d4])\r\n",
        "plt.title(\"First two principal components\")\r\n",
        "plt.xlabel(\"First principal component\")\r\n",
        "plt.ylabel(\"Second principal component\")\r\n",
        "plt.savefig(\"2.png\")\r\n",
        "plt.cla()\r\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "RMplgkohzlQe",
        "outputId": "815f30c7-c840-4c48-ebe8-d6608a83ecf9"
      },
      "source": [
        "# using kMeans on the data\r\n",
        "kmeans = KMeans(random_state=0,n_clusters=4).fit(pC)\r\n",
        "k_centers = kmeans.cluster_centers_\r\n",
        "\r\n",
        "pC1 = pca.fit_transform(k_centers)\r\n",
        "x1_coor, y1_coor = pC1[:,0], pC1[:,1]\r\n",
        "#Plotting the result on top of the scatter plot with the PCA analysis\r\n",
        "plt.scatter(x_coor, y_coor, c=['b' if i==0 else 'r' if i ==22 else 'black' if i==23 else 'g' for i in y1], s=10)\r\n",
        "plt.scatter(x1_coor, y1_coor, c='purple',marker='D', s=80)\r\n",
        "d5 = mpatches.Patch(color='purple', label='cluster centers')\r\n",
        "plt.legend(handles=[d1, d2, d3, d4, d5])\r\n",
        "plt.title(\"First two principal components\")\r\n",
        "plt.xlabel(\"First principal component\")\r\n",
        "plt.ylabel(\"Second principal component\")\r\n",
        "plt.savefig(\"3.png\")\r\n",
        "plt.cla()\r\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xXacay3oXm",
        "outputId": "c6fc8cf2-95eb-49af-b043-aac549e9b9b4"
      },
      "source": [
        "#Using the logistic regression model\r\n",
        "logReg = LogisticRegression(multi_class='multinomial',solver ='newton-cg').fit(x1, y1)\r\n",
        "\r\n",
        "yhat = logReg.predict(x1)\r\n",
        "yhat1 = logReg.predict(x_test1)\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "# Printing the zero one loss result\r\n",
        "print(zero_one_loss(y1, yhat))\r\n",
        "print(zero_one_loss(y_test1, yhat1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.031847133757961776\n",
            "0.11641791044776117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90JVxXFP9pZI",
        "outputId": "36041bd5-f41f-4f01-bcb6-73298b21434d"
      },
      "source": [
        "# Using the random forest classifier with square root of features\r\n",
        "clf = RandomForestClassifier(n_estimators=200, random_state=0,max_features='auto', oob_score=True)\r\n",
        "clf.fit(x1, y1)\r\n",
        "grid_predictions1 = clf.predict(x1)\r\n",
        "# Printing the zero one loss result\r\n",
        "print(zero_one_loss(y1, grid_predictions1)) \r\n",
        "print(1 - clf.oob_score_)\r\n",
        "\r\n",
        "clf1 = RandomForestClassifier(n_estimators=200, random_state=0,max_features='auto', oob_score=True)\r\n",
        "clf1.fit(x1, y1)\r\n",
        "grid_predictions11 = clf1.predict(x_test1)\r\n",
        "# Printing the zero one loss result\r\n",
        "print(zero_one_loss(y_test1, grid_predictions11))\r\n",
        "print(1 - clf1.oob_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.06369426751592355\n",
            "0.08358208955223878\n",
            "0.06369426751592355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wC3GiNf-_RQg",
        "outputId": "d0a5bfef-6459-4073-9cb0-90c11ebe379c"
      },
      "source": [
        "# Using the random forest classifier with all features \r\n",
        "clf2 = RandomForestClassifier(n_estimators=200, random_state=0,max_features=61, oob_score=True)\r\n",
        "clf2.fit(x1, y1)\r\n",
        "grid_predictions2 = clf2.predict(x1)\r\n",
        "# Printing the zero one loss result\r\n",
        "print(zero_one_loss(y1, grid_predictions2))\r\n",
        "print(1 - clf2.oob_score_)\r\n",
        "\r\n",
        "\r\n",
        "clf3 = RandomForestClassifier(n_estimators=200, random_state=0,max_features=61, oob_score=True)\r\n",
        "clf3.fit(x1, y1)\r\n",
        "grid_predictions22 = clf3.predict(x_test1)\r\n",
        "# Printing the zero one loss result\r\n",
        "print(zero_one_loss(y_test1, grid_predictions22))\r\n",
        "print(1 - clf3.oob_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "0.08280254777070062\n",
            "0.06865671641791049\n",
            "0.08280254777070062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28UBbUmoHGWj",
        "outputId": "5c627158-27a7-4b45-be91-b6d3eace6e05"
      },
      "source": [
        "# using the k-nearest neighbor classifier with cross-validation \r\n",
        "knn = KNeighborsClassifier()\r\n",
        "p = {'n_neighbors': np.arange(1, 20)}\r\n",
        "grid = GridSearchCV(knn, p, cv = 10)\r\n",
        "grid.fit(x1, y1)\r\n",
        "bestK = grid.best_params_\r\n",
        "bestK1 = bestK.values()\r\n",
        "K1List = list(bestK1)\r\n",
        "kNeigh = K1List[0]\r\n",
        "print('best k = ', kNeigh)\r\n",
        "\r\n",
        "\r\n",
        "pred = grid.predict(x1)\r\n",
        "#print(\"Result of the KNN classifier: \", score)\r\n",
        "print(\"0-1 loss train = \", zero_one_loss(y1, pred))\r\n",
        "\r\n",
        "\r\n",
        "pred1 = grid.predict(x_test1)\r\n",
        "#print(\"Result of the KNN classifier: \", score)\r\n",
        "print(\"0-1 loss test = \", zero_one_loss(y_test1, pred1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best k =  8\n",
            "0-1 loss train =  0.2993630573248408\n",
            "0-1 loss test =  0.34925373134328364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frKN3JNcXs-y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}